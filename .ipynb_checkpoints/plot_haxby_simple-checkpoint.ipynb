{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Simple example of decoding: the Haxby data\n",
    "==============================================\n",
    "\n",
    "Here is a simple example of decoding, reproducing the Haxby 2001\n",
    "study on a face vs cat discrimination task in a mask of the ventral\n",
    "stream.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve and load the Haxby dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset created in /Users/pp01sanne/nilearn_data/haxby2001\n",
      "\n",
      "Downloading data from https://www.nitrc.org/frs/download.php/7868/mask.nii.gz ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloaded 2969 of 2969 bytes (100.0%,    0.0s remaining) ...done. (2 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://data.pymvpa.org/datasets/haxby2001/MD5SUMS ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloaded 408 of 408 bytes (100.0%,    0.0s remaining) ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://data.pymvpa.org/datasets/haxby2001/subj1-2010.01.14.tar.gz ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 314803244 of 314803244 bytes (100.0%,    0.0s remaining) ...done. (721 seconds, 12 min)\n",
      "Extracting data from /Users/pp01sanne/nilearn_data/haxby2001/b7061e6dfd4459484ab7c3872d37e765/subj1-2010.01.14.tar.gz..... done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First subject anatomical nifti image (3D) is at: /Users/pp01sanne/nilearn_data/haxby2001/subj1/anat.nii.gz\n",
      "First subject functional nifti images (4D) are at: /Users/pp01sanne/nilearn_data/haxby2001/subj1/bold.nii.gz\n"
     ]
    }
   ],
   "source": [
    "from nilearn import datasets\n",
    "# if you download these from python.\n",
    "haxby_dataset = datasets.fetch_haxby()\n",
    "\n",
    "# print basic information on the dataset\n",
    "print('First subject anatomical nifti image (3D) is at: %s' %\n",
    "      haxby_dataset.anat[0])\n",
    "print('First subject functional nifti images (4D) are at: %s' %\n",
    "      haxby_dataset.func[0])  # 4D data\n",
    "\n",
    "# Load the behavioral labels\n",
    "import numpy as np\n",
    "# Load target information as string and give a numerical identifier to each\n",
    "labels = np.recfromcsv(haxby_dataset.session_target[0], delimiter=\" \")\n",
    "\n",
    "# scikit-learn >= 0.14 supports text labels. You can replace this line by:\n",
    "# target = labels['labels']\n",
    "_, target = np.unique(labels['labels'], return_inverse=True)\n",
    "\n",
    "# Keep only data corresponding to faces or cats\n",
    "condition_mask = np.logical_or(labels['labels'] == b'face',\n",
    "                               labels['labels'] == b'cat')\n",
    "target = target[condition_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data: apply the mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiMasker\n",
    "# ventro-temporal mask -> it is a transformer -> 3D images => 2D feature spaces\n",
    "mask_filename = haxby_dataset.mask_vt[0]\n",
    "# For decoding, standardizing is often very important\n",
    "nifti_masker = NiftiMasker(mask_img=mask_filename, standardize=True)\n",
    "\n",
    "func_filename = haxby_dataset.func[0]\n",
    "# We give the nifti_masker a filename and retrieve a 2D array ready\n",
    "# for machine learning with scikit-learn\n",
    "fmri_masked = nifti_masker.fit_transform(func_filename)\n",
    "\n",
    "# Restrict the classification to the face vs cat discrimination\n",
    "fmri_masked = fmri_masked[condition_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216, 577)\n",
      "[[-1.7471174   1.29787993 -0.22555825 ..., -1.59941506 -1.20669711\n",
      "  -0.14274804]\n",
      " [-2.05748582  1.29787993 -0.19278905 ..., -1.63558471 -1.67683387\n",
      "   0.22036591]\n",
      " [-2.15447593  1.48567474 -0.58601946 ..., -1.88877153 -2.02564502\n",
      "   0.08832448]\n",
      " ..., \n",
      " [-0.27286759 -0.29837653 -1.35609555 ...,  1.41471434  0.73451281\n",
      "   1.70583212]\n",
      " [-0.05948933 -1.19979191 -1.99509501 ...,  1.24592304  0.78000987\n",
      "   0.64950061]\n",
      " [-1.00999248 -0.6927458  -1.68378758 ...,  1.12535787  0.9468326\n",
      "   1.30970788]]\n",
      "[3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 3 3 3\n",
      " 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 3 3 3 3\n",
      " 3 3 3 3 3 1 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(fmri_masked.shape)\n",
    "# it is a substantially reduced dataset.\n",
    "print(fmri_masked)\n",
    "\n",
    "\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216,)\n",
      "(216, 577)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we use a Support Vector Classification, with a linear kernel\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# set the kernel type\n",
    "svc = SVC(kernel='linear')\n",
    "\n",
    "# And we run it\n",
    "print(target.shape)\n",
    "print(fmri_masked.shape)\n",
    "svc.fit(fmri_masked, target)\n",
    "prediction = svc.predict(fmri_masked)\n",
    "len(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute prediction scores using cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "cv = KFold(n=len(fmri_masked), n_folds=5)\n",
    "cv_scores = []\n",
    "\n",
    "for train, test in cv:\n",
    "    svc.fit(fmri_masked[train], target[train])\n",
    "    prediction = svc.predict(fmri_masked[test])\n",
    "    cv_scores.append(np.sum(prediction == target[test])\n",
    "                     / float(np.size(target[test])))\n",
    "\n",
    "print(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the discriminating weights and save them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retrieve the SVC discriminating weights\n",
    "coef_ = svc.coef_\n",
    "\n",
    "# Reverse masking thanks to the Nifti Masker\n",
    "coef_img = nifti_masker.inverse_transform(coef_)\n",
    "\n",
    "# Save the coefficients as a Nifti image\n",
    "coef_img.to_filename('haxby_svc_weights.nii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the discriminating weights over the mean EPI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nilearn.image import mean_img\n",
    "from nilearn.plotting import plot_roi, plot_stat_map, show\n",
    "\n",
    "mean_epi = mean_img(func_filename)\n",
    "plot_stat_map(coef_img, mean_epi, title=\"SVM weights\", display_mode=\"yx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot also the mask that was computed by the NiftiMasker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roi(nifti_masker.mask_img_, mean_epi, title=\"Mask\", display_mode=\"yx\")\n",
    "\n",
    "show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
